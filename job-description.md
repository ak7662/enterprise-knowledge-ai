Job highlights
7+ years in AI/ML engineering with 3+ years in LLM/NLP/RAG systems; strong Python and ML frameworks proficiency
Architect, build, and deploy LLM and RAG-based systems; optimize AI systems for scalability and accuracy; ensure production-quality code
Job match score
Early Applicant
Keyskills
Location
Work Experience
Job description
Job Title: AI Technical Lead (GenAI / LLM / RAG)
Location: Hyderabad (Hybrid)
Experience: 712 Years
Role Type: Individual Contributor (Hands-on)
Reporting To: CTO

About the Role
We are building next-generation AI capabilities for a global, data-driven B2B SaaS platform used by large enterprise customers. We are looking for a hands-on AI Technical Lead who will work closely with the CTO to architect, build, and deploy production-grade GenAI systems.
This is a deep technical role, not a people management position. You will own AI architecture, implementation, and delivery of real-world AI features used at scale.

Key Responsibilities
AI Architecture & GenAI Systems
Architect, build, and deploy LLM and RAG-based systems for enterprise SaaS products
Design end-to-end RAG pipelines (document chunking, embeddings, vector databases, ranking, evaluation)
Develop agentic AI workflows for multi-step automation and intelligent decision-making
Optimize AI systems for scalability, latency, cost, and accuracy
Engineering & Collaboration
Partner with AI Engineers, Product Managers, and the CTO to translate business requirements into robust AI solutions
Define best practices for LLM orchestration, evaluation, monitoring, and debugging
Ensure production-quality code and system reliability
MLOps & Production Readiness
Implement observability, monitoring, and evaluation for AI systems
Work with DevOps and Data Engineering teams to deploy scalable AI pipelines
Contribute to governance, documentation, and reproducibility standards
Security & Compliance
Ensure AI implementations follow best practices for data security, PII handling, and prompt safety
Support enterprise compliance requirements such as SOC 2 and GDPR

Required Skills & Experience
Must Have
7+ years of experience in AI/ML engineering
3+ years of hands-on experience building LLM / NLP / RAG systems in production
Proven experience delivering AI features used by real users in a SaaS or enterprise environment
Strong proficiency in Python and ML frameworks (PyTorch / TensorFlow / scikit-learn)
Experience with vector databases: Pinecone, Chroma, FAISS, Weaviate
Hands-on experience with LangChain, LlamaIndex, or similar GenAI frameworks
Experience deploying AI systems on AWS, GCP, or Azure
Solid understanding of MLOps, model evaluation, and continuous delivery
Good to Have
Experience with agentic AI frameworks (CrewAI, AutoGen, tool-based agents)
Experience integrating external APIs (Search, Crawlers, OCR, third-party data sources)
Background in enterprise SaaS or data-intensive platforms

Role: NLP / DL Engineering / Architect
Industry Type: Recruitment / Staffing
Department: Data Science & Analytics
Employment Type: Full Time, Permanent
Role Category: Data Science & Machine Learning
Education
UG: Any Graduate
Key Skills
Skills highlighted with ‘‘ are preferred keyskills
aiAimlrag
Vector DatabaseNatural Language ProcessingRetrieval Augmented GenerationllmMlPython







Job highlights
Bachelor s degree in Computer Science,Engineering,or a related quantitative field
Required Education .
Experience deploying on Google Cloud Platform (GCP) with Vertex AI,and IBM WatsonX . .
Experience implementing Model Context Protocol (MCP) for agent coordination
Job match score
Early Applicant
Keyskills
Location
Work Experience
Job description
We are seeking a highly skilled AI Engineer experience in Software Development, Data Science, or Machine Learning to design, develop, and deploy cutting-edge AI systems leveraging Large Language Models (LLMs), Chatbots, Retrieval-Augmented Generation (RAG), and agentic AI architectures.
This role involves hands-on development with LLMs, embeddings, RAG pipelines, and multi-agent systems using modern frameworks like LangChain, LangGraph, and LlamaIndex. The ideal candidate has experience with Vertex AI on GCP and IBM WatsonX, fine-tuning, and Agent Development Kits (ADKs), and is excited about building scalable, production-grade AI platforms.
Responsibilities
Agentic AI Development:
Design, build, and deploy agentic AI systems using frameworks such as LangChain, LangGraph, and related libraries.
Develop and deploy multi-agent systems capable of autonomous decision-making, reasoning, planning, and collaboration.
RAG Pipelines:
Implement and optimize retrieval-augmented generation (RAG) systems, ensuring agents can access and incorporate external knowledge sources for grounded, accurate responses .
LLM Engineering:
Fine-tune and prompt-engineer LLMs for task-specific reasoning, planning, and dynamic adaptation .
Work with LLM/SLM APIs, embeddings, and advanced generative AI techniques .
Enterprise AI Platform:
Lead the development of enterprise-grade AI platforms integrating LLMs, RAG, embeddings, and agentic AI protocols .
Implement and standardize Model Context Protocol (MCP) for consistent context management across models and agents.
MLOps Observability:
Establish and enforce best practices for MLOps, monitoring, and observability , ensuring scalable and maintainable AI solutions.
Applied AI Prototyping:
Rapidly prototype, experiment, and iterate to improve AI agent capabilities.
Collaboration Research:
Participate in the full research cycle : literature review, data exploration, experimentation, and presentation of findings.
Collaborate effectively with other engineers, researchers, and data scientists.
Contribute to the documentation and standardization of technical code and practices.
Required Education
Bachelor s degree in Computer Science, Engineering, or a related quantitative field. Master s or Ph.D. is a strong plus.
Required Experience
5+ years overall experience in software development, data science, or machine learning.
1+ year of hands-on experience developing AI applications with LLMs and systems such as retrieval-based methods, fine-tuning, or agent-based architectures .
1+ year of experience with frameworks like LangChain, LlamaIndex, OpenAI, or similar tools .
Required Technical Skills
Strong programming skills in Python and basics in SQL .
Expertise with LLM/SLM APIs, embeddings, and RAG systems .
Experience deploying on Google Cloud Platform (GCP) with Vertex AI, and IBM WatsonX .
Familiarity with agentic AI protocols and exposure to Agent Development Kits (ADKs) .
Preferred Qualifications
Experience implementing Model Context Protocol (MCP) for agent coordination.
Prior exposure to LangGraph, AutoGen, or related orchestration frameworks .
Knowledge of MLOps best practices (CI/CD for ML, observability, monitoring, scaling).
Familiarity with responsible AI principles (safety, fairness, interpretability).
Experience in enterprise-scale deployments of AI-driven platforms.
Contributions to open-source AI/ML projects are a plus.


Role: Blockchain Quality Assurance Engineer
Industry Type: Courier / Logistics
Department: Engineering - Software & QA
Employment Type: Full Time, Permanent
Role Category: Quality Assurance and Testing
Education
UG: Any Graduate
PG: Any Postgraduate, LLM in Law
Key Skills
Computer sciencePrototypeorchestrationdata scienceGCPMachine learningOpen sourceMonitoringSQLPython





Job highlights
Eligibility: Immediate joiners preferred with 4+ years of hands-on development experience
Job match score
Early Applicant
Keyskills
Location
Work Experience
Job description
Develop, implement, and optimize applications using Python with expertise in RAG (Retrieval Augmented Generation) framework.
Work on building and integrating AI/ML solutions leveraging LLMs and RAG pipelines.
Collaborate with cross-functional teams to deliver scalable and efficient solutions.
Troubleshoot, debug, and enhance existing systems for performance and accuracy.
Ensure high-quality coding standards, documentation, and deployment practices.
Eligibility: Immediate joiners preferred with 4+ years of hands-on development experience.
Need strong developers with python and RAG framework skills
Role: Full Stack Developer
Industry Type: BPM / BPO
Department: Engineering - Software & QA
Employment Type: Full Time, Permanent
Role Category: Software Development
Education
UG: Any Graduate
PG: Any Postgraduate
Key Skills
Skills highlighted with ‘‘ are preferred keyskills
Python
LLMsPython developmentPython DeveloperdocumentationAIRAG frameworkML



Job highlights
26 years of experience in AI engineering or backend engineering with strong production delivery ownership; expertise in Python, LangGraph, and Semantic Kernel
Build and operate agentic workflows, implement tool/function calling, develop RAG pipelines, design multi-agent systems, and ensure production readiness
Job match score
Early Applicant
Keyskills
Location
Work Experience
Job description
Role & responsibilities


Build and operate agentic workflows in Python using LangGraph and/or Semantic Kernel (LangChain/AutoGen/CrevAI as additional exposure).
Implement robust tool/function calling: schema validation, structured arguments/outputs, safe tool execution, retries, idempotency patterns, and permission-scoped tool access.
Develop and optimize RAG / Agentic RAG pipelines: ingestion, chunking, embeddings, hybrid retrieval, reranking, query planning, grounding, caching, and citation/trace strategies.
Design multi-agent systems: coordinator-worker, planner-executor, task decomposition, delegation, and optional human-in-the-loop checkpoints.
Drive evaluation and quality systems: regression suites, grounding/faithfulness checks, hallucination detection, task success metrics, latency/cost monitoring, and release gates.
Use cloud AI platform services (AWS preferred) for model access/orchestration and embeddings, and integrate these into enterprise-grade agent systems.
Ensure production readiness: observability (logs/metrics/traces), dashboards and alerting, and operational runbooks for common failure modes.
Apply security best practices for LLM/agentic systems: secrets handling, least privilege, prompt-injection defenses, content safeguards, audit logging, and safe integration boundaries.
Collaborate with architects, backend/platform engineers, and product teams to improve reliability, performance, cost, and UX.

Preferred candidate profile


26 years experience in AI engineering and/or backend engineering with strong production delivery ownership.
Strong Python engineering: async patterns, clean modular code, testing (pytest), profiling/performance debugging.
Hands-on experience delivering production agentic systems using LangGraph and/or Semantic Kernel, including tool orchestration and multi-step workflows.
Deep understanding of RAG systems end-to-end: ingestion retrieval grounding, including hybrid search and retrieval optimization concepts.
Multi-agent patterns and protocols: coordinator-worker, planner-executor, task decomposition; awareness of MCP and A2A-style interoperability patterns.
Evaluation and quality depth: experience with promptfoo, Phoenix/Arize (or equivalent), custom eval pipelines.

Cloud Platform AI Services Experience (AWS Preferred)

Using managed model/embedding services (e.g., AWS Bedrock or equivalents) and integrating them into production systems.
Practical Production Engineering Fundamentals

API design, auth/authz concepts, rate limiting, retries, idempotency, and resilient service patterns.
Experience Deploying Services


Role: Software Development - Other
Industry Type: Management Consulting
Department: Engineering - Software & QA
Employment Type: Full Time, Permanent
Role Category: Software Development
Education
UG: B.Tech/B.E. in Any Specialization
Key Skills
Skills highlighted with ‘‘ are preferred keyskills
LLMAgentic AiLanggraphFunction CallingAWS
Semantic KernelLangchainAI Agentspromptfooproduction agenticMCPRetrieval Augmented GenerationTask Decomposition